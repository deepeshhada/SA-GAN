{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E0 250 - Project 4 - Part 1.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaIex6NNPwdNbXvF3FtWTs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepeshhada/SA-GAN/blob/master/DCGAN%20-%20train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN7Fl2wvoWnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBO5Z578Rc17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "workers = 2\n",
        "batch_size = 8\n",
        "image_size = 32\n",
        "color_channels = 3\n",
        "latent_vector_dim = 100\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE6VeQcoorh3",
        "colab_type": "code",
        "outputId": "2edc3ee8-ae94-44c2-8596-b219bb7ebbe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.CenterCrop(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=workers\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCbaF14WW-VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initial_weights(m):\n",
        "    #  the authors specify that all model weights must be randomly initialized from a Normal distribution with mean=0, std=0.02\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz9fSzsXYlIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # 100 X 1 X 1\n",
        "            nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # 1024 X 4 X 4\n",
        "            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # 512 X 8 X 8\n",
        "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # 256 X 16 X 16\n",
        "            nn.ConvTranspose2d(in_channels=256, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh(),\n",
        "            # 3 x 32 x 32\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "\n",
        "G = Generator().to(device).apply(initial_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40vtwVAF3x_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # 3 x 32 x 32\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # 32 X 16 X 16\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # 64 X 8 X 8\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # 128 X 4 X 4\n",
        "            nn.Conv2d(in_channels=128, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "            # Discriminator score\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "D = Discriminator().to(device).apply(initial_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-idToFiKQHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = nn.BCELoss()\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "lr = 0.0002\n",
        "adam_beta1 = 0.5\n",
        "opt_D = optim.Adam(D.parameters(), lr=lr, betas=(adam_beta1, 0.999))\n",
        "opt_G = optim.Adam(G.parameters(), lr=lr, betas=(adam_beta1, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWYoAPDBMuQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_epochs = 5\n",
        "losses_G = []\n",
        "losses_D = []\n",
        "img_list = []\n",
        "iters = 0\n",
        "fixed_noise = torch.randn(128, latent_vector_dim, 1, 1, device=device)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        #   Step 1.1: Train Discriminator with minibatch of only real samples\n",
        "        D.zero_grad()\n",
        "        \n",
        "        real_inputs = data[0].to(device)\n",
        "        real_labels = torch.full((real_inputs.size(0), ), real_label, device=device, dtype=None)\n",
        "        real_outputs = D(real_inputs).view(-1)\n",
        "        err_D_real = loss_function(real_outputs, real_labels)\n",
        "        err_D_real.backward()\n",
        "        D_x = real_outputs.mean().item() # D(x)\n",
        "\n",
        "        #   Step 1.2: Train Discriminator with minibatch of only fake samples\n",
        "        noise = torch.randn(batch_size, latent_vector_dim, 1, 1, device=device) # creates a batch of 100 X 1 X 1 tensors\n",
        "        fake_inputs = G(noise).to(device)\n",
        "        fake_labels = torch.full((fake_inputs.size(0), ), fake_label, device=device, dtype=None)\n",
        "        fake_outputs = D(fake_inputs).view(-1)\n",
        "        err_D_fake = loss_function(fake_outputs, fake_labels)\n",
        "        err_D_fake.backward(retain_graph=True)\n",
        "        D_G_z1 = fake_outputs.mean().item() # D(G(z))\n",
        "        \n",
        "        err_D = err_D_real + err_D_fake\n",
        "        opt_D.step()\n",
        "\n",
        "        #   Step 2: Train Generator with minibatch of fake samples\n",
        "        G.zero_grad()\n",
        "        fake_labels = torch.full((fake_inputs.size(0), ), real_label, device=device, dtype=None) # real labels = 1 are fake labels for generator\n",
        "        fake_outputs = D(fake_inputs).view(-1)\n",
        "        err_G = loss_function(fake_outputs, fake_labels)\n",
        "        err_G.backward()\n",
        "        D_G_z2 = fake_outputs.mean().item() # D(G(z))\n",
        "        opt_G.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, max_epochs, i, len(trainloader),\n",
        "                     err_D.item(), err_G.item(), D_x, D_G_z1, D_G_z2))\n",
        "            \n",
        "        losses_G.append(err_G.item())\n",
        "        losses_D.append(err_D.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == max_epochs-1) and (i == len(trainloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = G(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lATNcHTtibe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}